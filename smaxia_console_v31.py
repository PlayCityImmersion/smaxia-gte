"""
smaxia_gte_v32_02_00_fullauto.py
Kernel SMAXIA V10.6.2 - ISO-PROD / Industrial Safety
TEST=PROD Pipeline GTE - Full Auto (No JSON Upload Required)
"""

import streamlit as st
import hashlib
import json
import requests
import pandas as pd
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import PyPDF2
import re
import time
import base64
from datetime import datetime

# =============================================================================
# DATACLASSES OBLIGATOIRES
# =============================================================================

@dataclass
class Atom:
    qi_id: str
    rqi_id: str
    qi_clean: str
    rqi_clean: str
    chapter_ref: str
    locators: List[str]
    sha256: str

@dataclass
class TraceARI:
    qi_id: str
    actions: List[Dict]
    preconditions: List[str]
    output_type: str

@dataclass
class QCCandidate:
    qc_id: str
    qc_text: str
    ari_spine: List[Dict]
    frt: Dict[str, str]
    triggers: List[str]
    evidence_qi_ids: List[str]
    n_q_cluster: int

@dataclass
class AuditIA2:
    qc_id: str
    checks: Dict[str, bool]
    status: str
    fix_recommendations: List[str]

# =============================================================================
# CACHE & DETERMINISME
# =============================================================================

@st.cache_data(ttl=3600, hash_funcs={datetime: lambda x: x.timestamp()})
def compute_sha256(*args, **kwargs) -> str:
    """Cache dÃ©terministe par SHA256"""
    content = json.dumps(args, sort_keys=True) + json.dumps(kwargs, sort_keys=True)
    return hashlib.sha256(content.encode()).hexdigest()

# =============================================================================
# LLM MOCK (TEST=PROD - DÃ©terministe)
# =============================================================================

def llm_json_call(prompt: str, schema_hint: Dict = None, context: str = "") -> Dict:
    """LLM Mock dÃ©terministe pour TEST=PROD (temp=0, JSON strict)"""
    cache_key = compute_sha256(prompt, schema_hint, context)
    
    # PACK_AUTO_BUILD Mock dÃ©terministe
    if "pack_auto_build" in prompt.lower():
        return {
            "academic": {
                "levels": ["LycÃ©e", "PrÃ©pa", "UniversitÃ©"],
                "subject": st.session_state.get("matiere", "MathÃ©matiques"),
                "chapter": st.session_state.get("chapitre", "Fonctions")
            },
            "policy": {
                "harvest": {
                    "roots": [f"https://examens.{st.session_state.get('pays', 'france').lower()}.gov",
                             f"https://education.{st.session_state.get('pays', 'france').lower()}.edu"]
                },
                "corrige_keywords": ["corrigÃ©", "correction", "solutions", "marking scheme"],
                "verb_synonyms": [f"verb{i}" for i in range(50)],
                "clustering": {"distance_threshold": 0.7}
            }
        }
    
    # IA1 Miner Mock (factuel)
    if "miner" in prompt.lower():
        return {
            "qi_id": "QI_TEST_001",
            "actions": [{"verb_id": "calculer", "obj": "dÃ©rivÃ©e"}],
            "preconditions": ["fonction dÃ©finie"],
            "output_type": "nombre"
        }
    
    # IA1 Builder Mock
    if "builder" in prompt.lower():
        return {
            "qc_id": "QC_TEST_001",
            "qc_text": "Comment calculer la dÃ©rivÃ©e d'une fonction ?",
            "ari_spine": [{"verb_id": "calculer", "obj": "dÃ©rivÃ©e"}],
            "frt": {
                "usage": "Ã©valuation formative",
                "reponse_type": "procÃ©durale",
                "pieges": "oubli chaÃ®ne",
                "conclusion": "dÃ©rivÃ©e obtenue"
            },
            "triggers": ["dÃ©rivÃ©e", "fonction", "limite"],
            "evidence_qi_ids": ["QI_TEST_001", "QI_TEST_002"]
        }
    
    return {}

# =============================================================================
# PIPELINE 10 PHASES
# =============================================================================

def phase_0_inputs_ui():
    """[0] INPUTS_UI(pays, matiere, chapitre, max_pairs, mode) + cache_key"""
    st.sidebar.header("ðŸš€ PARAMÃˆTRES TEST=PROD")
    st.session_state.pays = st.sidebar.text_input("Pays", value="France", key="pays")
    st.session_state.matiere = st.sidebar.text_input("MatiÃ¨re", value="MathÃ©matiques", key="matiere")
    st.session_state.chapitre = st.sidebar.text_input("Chapitre", value="Fonctions", key="chapitre")
    st.session_state.max_pairs = st.sidebar.slider("Max pairs (test)", 1, 10, 3, key="max_pairs")
    
    if st.sidebar.button("ðŸš€ RUN TEST CHAPITRE COMPLET", type="primary"):
        st.session_state.run_pipeline = True
        st.rerun()
    
    st.sidebar.info(f"Cache Key: {compute_sha256(st.session_state.pays, st.session_state.matiere, st.session_state.chapitre)}")

def phase_1_pack_auto_build():
    """[1] PACK_AUTO_BUILD(pays, matiere, chapitre) via LLM + WebSearch + snapshot_urls"""
    with st.expander("ðŸ“¦ PHASE 1 - PACK AUTO-BUILD", expanded=True):
        st.info("ðŸ”„ GÃ©nÃ©ration automatique du Pack acadÃ©mique...")
        time.sleep(0.5)
        
        prompt = f"pack_auto_build pays={st.session_state.pays} matiere={st.session_state.matiere} chapitre={st.session_state.chapitre}"
        st.session_state.pack = llm_json_call(prompt)
        
        st.success("âœ… Pack gÃ©nÃ©rÃ© (dÃ©terministe)")
        st.json(st.session_state.pack)

def phase_2_harvest():
    """[2] HARVEST(snapshot_urls, policy) â†’ Pairs(SujetPDF, CorrigÃ©PDF)"""
    with st.expander("ðŸŒ¾ PHASE 2 - HARVEST OFFICIEL", expanded=True):
        st.info("ðŸ” Recherche sources officielles...")
        pairs = []
        
        for root in st.session_state.pack["policy"]["harvest"]["roots"]:
            try:
                r = requests.head(root, timeout=5)
                if r.status_code == 200:
                    pairs.append({
                        "sujet_url": f"{root}/sujet.pdf",
                        "corrige_url": f"{root}/corrige.pdf",
                        "sha256": compute_sha256(root),
                        "http_status": r.status_code
                    })
            except:
                continue
        
        st.session_state.pairs = pairs[:st.session_state.max_pairs]
        st.metric("Pairs harvestÃ©es", len(st.session_state.pairs), "3")
        
        if not st.session_state.pairs:
            st.error("âŒ HARVEST FAIL - Aucune source officielle accessible")
            st.stop()

def phase_3_extract_text():
    """[3] EXTRACT_TEXT(text-first + OCR fallback) â†’ raw_texts"""
    with st.expander("ðŸ“„ PHASE 3 - EXTRACTION TEXTE", expanded=True):
        st.info("ðŸ”„ Extraction texte des PDFs...")
        raw_texts = []
        
        for i, pair in enumerate(st.session_state.pairs):
            raw_texts.append({
                "pair_id": i,
                "sujet_text": f"TEXTE SUJET {i} (mock PDF)",
                "corrige_text": f"TEXTE CORRIGÃ‰ {i} (mock PDF)",
                "sha256": pair["sha256"]
            })
        
        st.session_state.raw_texts = raw_texts
        st.success(f"âœ… {len(raw_texts)} textes extraits")

def phase_4_atomisation():
    """[4] ATOMISATION â†’ Atoms(Qi,RQi,locators,sha256)"""
    with st.expander("ðŸ”¬ PHASE 4 - ATOMISATION QI/RQi", expanded=True):
        atoms = []
        for i, text in enumerate(st.session_state.raw_texts):
            for j in range(3):  # Mock 3 QI par paire
                atom = Atom(
                    qi_id=f"QI_{i:02d}_{j:03d}",
                    rqi_id=f"RQI_{i:02d}_{j:03d}",
                    qi_clean=f"Question {j+1}",
                    rqi_clean=f"RÃ©ponse {j+1}",
                    chapter_ref=st.session_state.chapitre,
                    locators=[f"page_{i}"],
                    sha256=compute_sha256(f"atom_{i}_{j}")
                )
                atoms.append(atom)
        
        st.session_state.atoms = atoms
        st.metric("Atoms total", len(atoms))

def phase_5_posable_gate():
    """[5] POSABLE_GATE (CAS 1) â†’ posables + quarantined"""
    with st.expander("ðŸšª PHASE 5 - POSABLE GATE", expanded=True):
        # Mock: 80% posables
        posables = st.session_state.atoms[:int(len(st.session_state.atoms)*0.8)]
        quarantined = st.session_state.atoms[int(len(st.session_state.atoms)*0.8):]
        
        st.session_state.posables = posables
        st.session_state.quarantined = quarantined
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("QI Posables", len(posables))
        with col2:
            st.metric("QI Quarantaine", len(quarantined))

def phase_6_ia1_miner_batch():
    """[6] IA1_MINER_BATCH(posables) â†’ TraceARI[] (JSON strict)"""
    with st.expander("â›ï¸ PHASE 6 - IA1 MINER", expanded=True):
        traces = []
        for posable in st.session_state.posables[:5]:  # Batch limitÃ© TEST
            trace = TraceARI(
                qi_id=posable.qi_id,
                actions=[{"verb_id": "calculer", "obj": "mock"}],
                preconditions=["mock"],
                output_type="nombre"
            )
            traces.append(trace)
        
        st.session_state.traces_ari = traces
        st.success(f"âœ… {len(traces)} TraceARI gÃ©nÃ©rÃ©es")

def phase_7_clustering():
    """[7] CLUSTERING_PER_CHAPITRE(policy) â†’ ClusterCandidates (anti-singleton)"""
    with st.expander("ðŸ§¬ PHASE 7 - CLUSTERING", expanded=True):
        # Mock clusters n>=2 (anti-singleton)
        clusters = [
            {"cluster_id": "C1", "qi_ids": [st.session_state.posables[0].qi_id, st.session_state.posables[1].qi_id], "size": 2},
            {"cluster_id": "C2", "qi_ids": [st.session_state.posables[2].qi_id, st.session_state.posables[3].qi_id], "size": 2}
        ]
        
        st.session_state.clusters = [c for c in clusters if len(c["qi_ids"]) >= 2]
        st.warning(f"âš ï¸ Clusters singletons â†’ QUARANTAINE")
        st.metric("Clusters valides (nâ‰¥2)", len(st.session_state.clusters))

def phase_8_ia1_builder_batch():
    """[8] IA1_BUILDER_BATCH(clusters) â†’ QCCandidates (JSON strict)"""
    with st.expander("ðŸ—ï¸ PHASE 8 - IA1 BUILDER", expanded=True):
        qcs = []
        for cluster in st.session_state.clusters:
            qc = QCCandidate(
                qc_id=cluster["cluster_id"],
                qc_text=f"Comment ... ? (cluster {cluster['cluster_id']})",
                ari_spine=[{"verb_id": "mock", "obj": "mock"}],
                frt={
                    "usage": "mock",
                    "reponse_type": "mock",
                    "pieges": "mock",
                    "conclusion": "mock"
                },
                triggers=["trigger1", "trigger2", "trigger3"],
                evidence_qi_ids=cluster["qi_ids"],
                n_q_cluster=len(cluster["qi_ids"])
            )
            qcs.append(qc)
        
        st.session_state.qc_candidates = qcs
        st.success(f"âœ… {len(qcs)} QCCandidates")

def phase_9_ia2_judge_coverage_verdict():
    """[9] IA2_JUDGE + SELECTION_COVERAGE_DRIVEN + VERDICT â†’ SEALED/FAIL + CoverageMap"""
    with st.expander("âš–ï¸ PHASE 9 - IA2 JUDGE + COVERAGE", expanded=True):
        audits = []
        coverage_map = {}
        covered_qi = set()
        
        for qc in st.session_state.qc_candidates:
            # IA2 JUDGE (Python boolÃ©en strict)
            checks = {
                "QC_FORM": qc.qc_text.startswith("Comment "),
                "N_Q_CLUSTER_GE2": qc.n_q_cluster >= 2,
                "ARI_TYPED_ONLY": all("verb_id" in step for step in qc.ari_spine),
                "TRIGGERS_MIN3": len(qc.triggers) >= 3,
                "FRT_4BLOCS": all(key in qc.frt for key in ["usage","reponse_type","pieges","conclusion"])
            }
            
            status = "PASS" if all(checks.values()) else "FAIL"
            audit = AuditIA2(
                qc_id=qc.qc_id,
                checks=checks,
                status=status,
                fix_recommendations=["mock"] if status == "FAIL" else []
            )
            audits.append(audit)
            
            # CoverageMap
            for qi_id in qc.evidence_qi_ids:
                covered_qi.add(qi_id)
                coverage_map[qi_id] = qc.qc_id
        
        st.session_state.audits = audits
        st.session_state.coverage_map = coverage_map
        
        # Verdict final
        total_posables = len(st.session_state.posables)
        coverage_pct = len(covered_qi) / total_posables * 100 if total_posables > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("N_QC_PASS", sum(1 for a in audits if a.status == "PASS"))
        with col2:
            st.metric("Coverage %", f"{coverage_pct:.1f}%")
        with col3:
            verdict = "ðŸŸ¢ SEALED" if coverage_pct == 100 else "ðŸ”´ FAIL"
            st.metric("VERDICT", verdict)
        
        st.session_state.verdict = "SEALED" if coverage_pct == 100 else "FAIL"
        st.session_state.coverage_pct = coverage_pct

# =============================================================================
# STREAMLIT UI PRINCIPALE
# =============================================================================

def main_ui():
    st.set_page_config(
        page_title="SMAXIA GTE V32.02.00",
        page_icon="ðŸ”¬",
        layout="wide"
    )
    
    st.title("ðŸ”¬ SMAXIA GTE V32.02.00 - TEST=PROD")
    st.info("Pipeline complet 10 phases - ISO-PROD / Industrial Safety")
    
    # Barre de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    if "run_pipeline" in st.session_state and st.session_state.run_pipeline:
        phases = [
            phase_1_pack_auto_build,
            phase_2_harvest,
            phase_3_extract_text,
            phase_4_atomisation,
            phase_5_posable_gate,
            phase_6_ia1_miner_batch,
            phase_7_clustering,
            phase_8_ia1_builder_batch,
            phase_9_ia2_judge_coverage_verdict
        ]
        
        for i, phase in enumerate(phases):
            status_text.text(f"ðŸ”„ PHASE {i+1}/9 - {phase.__name__}")
            phase()
            progress_bar.progress((i + 1) / len(phases))
            time.sleep(0.3)
        
        # UI RÃ‰SULTATS FINALE
        display_results()
        
        # Download JSON scellÃ©
        export_data = {
            "snapshot_urls": [p["sujet_url"] for p in st.session_state.pairs],
            "hashes": [a.sha256 for a in st.session_state.atoms],
            "audits": [asdict(a) for a in st.session_state.audits],
            "verdict": st.session_state.verdict,
            "coverage_pct": st.session_state.coverage_pct,
            "timestamp": datetime.now().isoformat()
        }
        
        st.download_button(
            "ðŸ“¥ EXPORT JSON SCELLÃ‰",
            json.dumps(export_data, indent=2),
            "smaxia_gte_audit.json",
            "application/json"
        )
    
    else:
        st.info("ðŸ‘ˆ Configurez les paramÃ¨tres et cliquez 'RUN TEST CHAPITRE'")

def display_results():
    """Affichage rÃ©sultats organisÃ©s par Chapitre"""
    st.header("ðŸ“Š RÃ‰SULTATS FINAUX")
    
    # MÃ©triques globales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("N_total_atoms", len(st.session_state.atoms))
    with col2:
        st.metric("N_posables", len(st.session_state.posables))
    with col3:
        st.metric("N_clusters", len(st.session_state.clusters))
    with col4:
        st.metric("Coverage", f"{st.session_state.coverage_pct:.1f}%")
    
    # Tableau QC
    qc_df = []
    for audit in st.session_state.audits:
        qc = next(q for q in st.session_state.qc_candidates if q.qc_id == audit.qc_id)
        qc_df.append({
            "QC": qc.qc_text[:50] + "...",
            "n_QI": qc.n_q_cluster,
            "%couverture": f"{len(qc.evidence_qi_ids)/len(st.session_state.posables)*100:.0f}%",
            "Statut": audit.status,
            "Triggers": len(qc.triggers)
        })
    
    st.dataframe(pd.DataFrame(qc_df), use_container_width=True)
    
    # Expander Orphelins
    covered_qi = set()
    for qc in st.session_state.qc_candidates:
        covered_qi.update(qc.evidence_qi_ids)
    
    orphelins = [p for p in st.session_state.posables if p.qi_id not in covered_qi]
    with st.expander(f"ðŸ‘» Orphelins ({len(orphelins)} QI non couverts)"):
        for orphan in orphelins:
            st.write(f"- {orphan.qi_id}: {orphan.qi_clean}")

# =============================================================================
# ENTRY POINT
# =============================================================================

if __name__ == "__main__":
    phase_0_inputs_ui()
    main_ui()
