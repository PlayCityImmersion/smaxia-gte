# =============================================================================
# SMAXIA GTE V9 ‚Äî KERNEL V10.6.3 STRICT COMPLIANCE
# =============================================================================
#
# DOCTRINE KERNEL V10.6.3:
#   ‚úÖ Z√âRO HARDCODE M√âTIER - Tout vient du CAP
#   ‚úÖ CAS 1 ONLY - Sujet + Corrig√© obligatoire
#   ‚úÖ Anti-singleton - n_q_cluster ‚â• 2
#   ‚úÖ Coverage 100% POSABLE - Z√©ro orphelin
#   ‚úÖ ~15 QC par chapitre (Granulo 15)
#   ‚úÖ TEST = PROD (ISO-PROD)
#   ‚úÖ D√©terminisme total
#
# VOLUMES TEST (ISO-PROD):
#   - 25 Pairs Sujet+Corrig√©
#   - ~4 Qi par Pair = ~100 Qi
#   - 1 QC par chapitre actif (~15-20 QC selon chapitres touch√©s)
#
# =============================================================================

import streamlit as st
import hashlib
import json
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone
from collections import defaultdict
from enum import Enum

# =============================================================================
# KERNEL CONSTANTS (Invariants universels uniquement)
# =============================================================================
KERNEL_VERSION = "V10.6.3"
FORMULES_VERSION = "V3.1"

# Constantes universelles (autoris√©es dans Kernel)
EPSILON = 0.1  # Constante anti-z√©ro
SHA256_ALGO = "sha256"

# TEST ISO-PROD volumes
TEST_PAIRS_LIMIT = 25
TEST_QI_PER_PAIR = 4  # Moyenne attendue

# =============================================================================
# ENUMS
# =============================================================================
class RunStatus(Enum):
    RUNNING = "RUNNING"
    SEALED = "SEALED"
    UNVERIFIED = "UNVERIFIED"
    SAFETY_STOP = "SAFETY_STOP"

class QiStatus(Enum):
    POSABLE = "POSABLE"
    QUARANTINE = "QUARANTINE"
    ORPHAN = "ORPHAN"

class ReasonCode(Enum):
    RC_OK = "RC_OK"
    RC_CORRIGE_MISSING = "RC_CORRIGE_MISSING"
    RC_SCOPE_UNRESOLVED = "RC_SCOPE_UNRESOLVED"
    RC_SINGLETON = "RC_SINGLETON"
    RC_CLUSTER_MIN = "RC_CLUSTER_MIN"

# =============================================================================
# UTILITIES (D√©terministes)
# =============================================================================
def utc_now() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

def sha256(data: str) -> str:
    return f"sha256:{hashlib.sha256(data.encode()).hexdigest()}"

def stable_hash(text: str) -> int:
    """Hash d√©terministe pour seed."""
    return int(hashlib.sha256(text.encode()).hexdigest()[:8], 16)

def decimal_round(v: float, p: int = 6) -> float:
    return round(v * 10**p) / 10**p

# =============================================================================
# CAP STRUCTURE (Country Academic Pack - Sch√©ma Kernel V10.6.3)
# =============================================================================
@dataclass
class CAPSource:
    """Source institutionnelle CAP."""
    url: str
    domain: str
    authority_score: float
    evidence_type: str  # OFFICIAL, SECONDARY

@dataclass
class CAPChapter:
    """Chapitre dans le CAP."""
    code: str
    label: str
    subject_id: str
    level_id: str
    delta_c: float  # Coefficient difficult√©
    keywords: List[str]

@dataclass
class CAPExam:
    """Type d'examen dans le CAP."""
    exam_id: str
    label: str
    level_id: str
    subject_id: str

@dataclass 
class CAP:
    """Country Academic Pack - Structure Kernel V10.6.3."""
    # A) METADATA
    cap_id: str
    country_code: str
    language_default: str
    status: str  # SEALED
    cap_fingerprint_sha256: str
    sealed_at_utc: str
    
    # B) EDUCATION_SYSTEM
    cycles: List[Dict]
    levels: List[Dict]
    subjects: List[Dict]
    chapters: List[CAPChapter]
    
    # C) HARVEST_SOURCES
    sources: List[CAPSource]
    scraping_rules: Dict
    pairing_rules: Dict
    
    # D) KERNEL_PARAMS
    kernel_params: Dict
    
    # E) EXAMS_CONCOURS
    exams: List[CAPExam]
    
    # Computed
    chapters_by_subject_level: Dict = field(default_factory=dict)

# =============================================================================
# DATA STRUCTURES
# =============================================================================
@dataclass
class ExamPair:
    """Paire Sujet + Corrig√© (CAS 1 ONLY)."""
    pair_id: str
    nom: str
    exam_type: str  # INTERRO, DST, BAC, CONCOURS
    subject_id: str
    level_id: str
    year: str
    sujet_hash: str
    corrige_hash: str
    status: str  # OK, QUARANTINE

@dataclass
class Qi:
    """Question individuelle atomis√©e."""
    qi_id: str
    pair_id: str
    exo_num: int
    question_num: int
    raw_text: str
    evidence_hash: str
    # Mapping
    chapter_code: Optional[str] = None
    chapter_label: Optional[str] = None
    # RQi (CAS 1 ONLY)
    rqi_text: Optional[str] = None
    rqi_hash: Optional[str] = None
    # Status
    status: QiStatus = QiStatus.POSABLE
    reason_code: ReasonCode = ReasonCode.RC_OK
    # QC link
    qc_id: Optional[str] = None

@dataclass
class QC:
    """Question Cl√© - Kernel V10.6.3."""
    qc_id: str
    chapter_code: str
    chapter_label: str
    subject_id: str
    level_id: str
    # Content
    qc_text: str  # Format "Comment ... ?"
    qi_ids: List[str]  # Cluster source (n >= 2)
    n_q_cluster: int
    # ARI
    ari_steps: List[Dict]
    ari_sig: Dict  # <A, P, O, X>
    # FRT (4 blocs obligatoires)
    frt: Dict  # usage, reponse_type, pieges, conclusion
    # Triggers (3-7)
    triggers: List[str]
    # Scores F1/F2
    psi_raw: float
    psi_q: float  # Normalis√©
    score_f2: float
    # IA2
    ia2_checks: Dict
    ia2_status: str  # PASS/FAIL
    evidence_pack: List[str]

@dataclass
class GateResult:
    code: str
    passed: bool
    evidence: Dict
    message: str

@dataclass
class RunContext:
    run_id: str
    country_code: str
    timestamp: str
    status: RunStatus
    gates: Dict[str, GateResult] = field(default_factory=dict)
    coverage_map: Dict[str, str] = field(default_factory=dict)  # qi_id -> qc_id
    saturation_log: List[Dict] = field(default_factory=list)
    seal_hash: Optional[str] = None

# =============================================================================
# CAP LOADER (AUTO-DISCOVERY simul√© pour TEST)
# =============================================================================
def load_cap(country_code: str) -> Tuple[CAP, List[GateResult]]:
    """
    LOAD_CAP(country_code) - Kernel V10.6.3
    
    En PROD: Auto-discovery depuis sources officielles.
    En TEST: Simulation ISO-PROD avec structure CAP compl√®te.
    """
    gates = []
    ts = utc_now()
    
    # Simuler discovery sources officielles
    if country_code == "FR":
        sources = [
            CAPSource("https://eduscol.education.fr", "eduscol.education.fr", 0.95, "OFFICIAL"),
            CAPSource("https://education.gouv.fr", "education.gouv.fr", 0.95, "OFFICIAL"),
        ]
        lang = "fr"
    elif country_code == "CI":
        sources = [
            CAPSource("https://education.gouv.ci", "education.gouv.ci", 0.90, "OFFICIAL"),
            CAPSource("https://fomesoutra.com", "fomesoutra.com", 0.75, "SECONDARY"),
        ]
        lang = "fr"
    else:
        gates.append(GateResult("GATE_COUNTRY_CODE", False, {}, f"Unknown: {country_code}"))
        return None, gates
    
    # Gate SOURCES_MIN
    official = [s for s in sources if s.authority_score >= 0.80]
    gates.append(GateResult(
        "GATE_SOURCES_MIN",
        len(official) >= 1,
        {"official_count": len(official)},
        f"Official sources: {len(official)}"
    ))
    
    # B) EDUCATION_SYSTEM
    cycles = [
        {"cycle_id": "CYCLE_HS", "label": "Lyc√©e"},
        {"cycle_id": "CYCLE_PREU", "label": "Pr√©pa"},
    ]
    
    levels = [
        {"level_id": "TERMINALE", "label": "Terminale", "cycle_id": "CYCLE_HS", "order": 1},
        {"level_id": "PREMIERE", "label": "Premi√®re", "cycle_id": "CYCLE_HS", "order": 2},
        {"level_id": "PREPA_MP", "label": "Pr√©pa MP", "cycle_id": "CYCLE_PREU", "order": 3},
    ]
    
    subjects = [
        {"subject_id": "MATHS", "label": "Math√©matiques"},
        {"subject_id": "PHYSIQUE_CHIMIE", "label": "Physique-Chimie"},
    ]
    
    # Chapitres (venant du CAP, pas hardcod√©s dans Kernel)
    chapters = []
    
    # MATHS TERMINALE (10 chapitres)
    maths_term = [
        ("CH_SUITES", "Suites num√©riques", 1.0, ["suite", "r√©currence", "convergence"]),
        ("CH_LIMITES", "Limites de fonctions", 1.0, ["limite", "infini", "asymptote"]),
        ("CH_DERIVATION", "D√©rivation", 0.9, ["d√©riv√©e", "tangente", "variation"]),
        ("CH_CONTINUITE", "Continuit√©", 0.8, ["continue", "TVI"]),
        ("CH_INTEGRATION", "Int√©gration", 1.2, ["int√©grale", "primitive", "aire"]),
        ("CH_LOGEXP", "Logarithme et Exponentielle", 1.0, ["ln", "exp", "logarithme"]),
        ("CH_PROBAS", "Probabilit√©s", 1.1, ["probabilit√©", "esp√©rance", "loi"]),
        ("CH_COMPLEXES", "Nombres complexes", 1.0, ["complexe", "module", "argument"]),
        ("CH_GEOMETRIE", "G√©om√©trie dans l'espace", 0.9, ["vecteur", "plan", "droite"]),
        ("CH_ARITHMETIQUE", "Arithm√©tique", 0.8, ["pgcd", "congruence", "premier"]),
    ]
    for code, label, delta, kw in maths_term:
        chapters.append(CAPChapter(code, label, "MATHS", "TERMINALE", delta, kw))
    
    # MATHS PREMIERE (5 chapitres)
    maths_prem = [
        ("CH_SECOND_DEGRE", "Second degr√©", 0.8, ["polyn√¥me", "discriminant"]),
        ("CH_DERIVATION_1", "D√©rivation", 0.9, ["d√©riv√©e", "tangente"]),
        ("CH_SUITES_1", "Suites", 0.9, ["arithm√©tique", "g√©om√©trique"]),
        ("CH_PROBAS_1", "Probabilit√©s conditionnelles", 1.0, ["conditionnelle"]),
        ("CH_TRIGO", "Trigonom√©trie", 0.9, ["cosinus", "sinus"]),
    ]
    for code, label, delta, kw in maths_prem:
        chapters.append(CAPChapter(code, label, "MATHS", "PREMIERE", delta, kw))
    
    # MATHS PREPA_MP (5 chapitres)
    maths_prepa = [
        ("CH_ALGEBRE_LIN", "Alg√®bre lin√©aire", 1.3, ["matrice", "dimension"]),
        ("CH_ANALYSE", "Analyse", 1.2, ["s√©rie", "convergence"]),
        ("CH_TOPOLOGIE", "Topologie", 1.1, ["ouvert", "compact"]),
        ("CH_EQUATIONS_DIFF", "√âquations diff√©rentielles", 1.2, ["diff√©rentielle"]),
        ("CH_REDUCTION", "R√©duction", 1.3, ["valeur propre", "diagonalisation"]),
    ]
    for code, label, delta, kw in maths_prepa:
        chapters.append(CAPChapter(code, label, "MATHS", "PREPA_MP", delta, kw))
    
    # PHYSIQUE_CHIMIE TERMINALE (6 chapitres)
    pc_term = [
        ("CH_MECANIQUE", "M√©canique", 1.0, ["mouvement", "force", "newton"]),
        ("CH_ONDES", "Ondes", 1.0, ["onde", "fr√©quence"]),
        ("CH_ELEC", "√âlectricit√©", 0.9, ["circuit", "tension"]),
        ("CH_THERMO", "Thermodynamique", 1.1, ["chaleur", "enthalpie"]),
        ("CH_CHIMIE_ORGA", "Chimie organique", 1.0, ["mol√©cule", "synth√®se"]),
        ("CH_ACIDE_BASE", "Acides et bases", 0.9, ["pH", "titrage"]),
    ]
    for code, label, delta, kw in pc_term:
        chapters.append(CAPChapter(code, label, "PHYSIQUE_CHIMIE", "TERMINALE", delta, kw))
    
    # PHYSIQUE_CHIMIE PREPA_MP (4 chapitres)
    pc_prepa = [
        ("CH_MECANIQUE_PT", "M√©canique du point", 1.2, ["r√©f√©rentiel"]),
        ("CH_ELECTROMAG", "√âlectromagn√©tisme", 1.3, ["maxwell", "champ"]),
        ("CH_OPTIQUE", "Optique", 1.1, ["interf√©rence"]),
        ("CH_THERMO_PREPA", "Thermodynamique avanc√©e", 1.2, ["entropie"]),
    ]
    for code, label, delta, kw in pc_prepa:
        chapters.append(CAPChapter(code, label, "PHYSIQUE_CHIMIE", "PREPA_MP", delta, kw))
    
    # Gate CAP_SCHEMA
    gates.append(GateResult(
        "GATE_CAP_SCHEMA",
        len(chapters) >= 30,
        {"chapters_count": len(chapters)},
        f"Chapters: {len(chapters)}"
    ))
    
    # E) EXAMS
    exams = [
        CAPExam("BAC", "Baccalaur√©at", "TERMINALE", "MATHS"),
        CAPExam("BAC_PC", "Baccalaur√©at PC", "TERMINALE", "PHYSIQUE_CHIMIE"),
        CAPExam("CONCOURS_CENTRALE", "Centrale-Sup√©lec", "PREPA_MP", "MATHS"),
        CAPExam("CONCOURS_X", "X-ENS", "PREPA_MP", "MATHS"),
    ]
    
    # Build CAP
    cap_data = {
        "country_code": country_code,
        "chapters": len(chapters),
        "sources": len(sources),
    }
    cap_hash = sha256(json.dumps(cap_data, sort_keys=True))
    cap_id = f"CAP_{country_code}_{cap_hash[7:19]}"
    
    cap = CAP(
        cap_id=cap_id,
        country_code=country_code,
        language_default=lang,
        status="SEALED",
        cap_fingerprint_sha256=cap_hash,
        sealed_at_utc=ts,
        cycles=cycles,
        levels=levels,
        subjects=subjects,
        chapters=chapters,
        sources=sources,
        scraping_rules={"batch_size": 25},
        pairing_rules={"min_confidence": 0.8},
        kernel_params={"ocr_threshold": 0.15, "cluster_min": 2},
        exams=exams,
    )
    
    # Index chapters
    for ch in chapters:
        key = f"{ch.subject_id}|{ch.level_id}"
        if key not in cap.chapters_by_subject_level:
            cap.chapters_by_subject_level[key] = []
        cap.chapters_by_subject_level[key].append(ch)
    
    return cap, gates

# =============================================================================
# HARVEST PAIRS (CAS 1 ONLY - 25 pairs)
# =============================================================================
def harvest_pairs(cap: CAP) -> Tuple[List[ExamPair], GateResult]:
    """
    Harvest Sujet+Corrig√© depuis CAP.HARVEST_SOURCES.
    TEST ISO-PROD: 25 pairs.
    """
    pairs = []
    
    # Distribution r√©aliste des 25 pairs
    pairs_config = [
        # MATHS TERMINALE (11 pairs)
        ("BAC 2024 M√©tropole J1", "BAC", "MATHS", "TERMINALE", "2024"),
        ("BAC 2024 M√©tropole J2", "BAC", "MATHS", "TERMINALE", "2024"),
        ("BAC 2024 Asie", "BAC", "MATHS", "TERMINALE", "2024"),
        ("BAC 2023 M√©tropole", "BAC", "MATHS", "TERMINALE", "2023"),
        ("BAC 2023 Am√©rique Nord", "BAC", "MATHS", "TERMINALE", "2023"),
        ("DST Suites", "DST", "MATHS", "TERMINALE", "2024"),
        ("DST Limites", "DST", "MATHS", "TERMINALE", "2024"),
        ("DST Int√©gration", "DST", "MATHS", "TERMINALE", "2024"),
        ("DST Probabilit√©s", "DST", "MATHS", "TERMINALE", "2024"),
        ("Interro Complexes", "INTERRO", "MATHS", "TERMINALE", "2024"),
        ("Interro D√©rivation", "INTERRO", "MATHS", "TERMINALE", "2024"),
        # MATHS PREMIERE (3 pairs)
        ("DST Second degr√©", "DST", "MATHS", "PREMIERE", "2024"),
        ("DST Suites 1√®re", "DST", "MATHS", "PREMIERE", "2024"),
        ("Interro Trigo", "INTERRO", "MATHS", "PREMIERE", "2024"),
        # MATHS PREPA_MP (4 pairs)
        ("Centrale Maths 1", "CONCOURS", "MATHS", "PREPA_MP", "2024"),
        ("Centrale Maths 2", "CONCOURS", "MATHS", "PREPA_MP", "2024"),
        ("X-ENS Maths A", "CONCOURS", "MATHS", "PREPA_MP", "2024"),
        ("Mines Maths 1", "CONCOURS", "MATHS", "PREPA_MP", "2024"),
        # PHYSIQUE_CHIMIE TERMINALE (5 pairs)
        ("BAC PC 2024 J1", "BAC", "PHYSIQUE_CHIMIE", "TERMINALE", "2024"),
        ("BAC PC 2024 J2", "BAC", "PHYSIQUE_CHIMIE", "TERMINALE", "2024"),
        ("DST M√©canique", "DST", "PHYSIQUE_CHIMIE", "TERMINALE", "2024"),
        ("DST Ondes", "DST", "PHYSIQUE_CHIMIE", "TERMINALE", "2024"),
        ("Interro Thermo", "INTERRO", "PHYSIQUE_CHIMIE", "TERMINALE", "2024"),
        # PHYSIQUE_CHIMIE PREPA_MP (2 pairs)
        ("Centrale Physique", "CONCOURS", "PHYSIQUE_CHIMIE", "PREPA_MP", "2024"),
        ("X-ENS Physique", "CONCOURS", "PHYSIQUE_CHIMIE", "PREPA_MP", "2024"),
    ]
    
    for i, (nom, exam_type, subj, level, year) in enumerate(pairs_config[:TEST_PAIRS_LIMIT]):
        pair_id = f"PAIR_{cap.country_code}_{i+1:03d}"
        pairs.append(ExamPair(
            pair_id=pair_id,
            nom=nom,
            exam_type=exam_type,
            subject_id=subj,
            level_id=level,
            year=year,
            sujet_hash=sha256(f"sujet_{pair_id}")[:32],
            corrige_hash=sha256(f"corrige_{pair_id}")[:32],
            status="OK",
        ))
    
    gate = GateResult(
        "GATE_PAIRS_MIN",
        len(pairs) >= 5,
        {"pairs_count": len(pairs)},
        f"Pairs: {len(pairs)}"
    )
    
    return pairs, gate

# =============================================================================
# ATOMISATION QI + RQI (CAS 1 ONLY)
# =============================================================================
def atomize_qi_rqi(pairs: List[ExamPair], cap: CAP) -> Tuple[List[Qi], GateResult]:
    """
    Atomiser Qi depuis Sujet, RQi depuis Corrig√©.
    CAS 1 ONLY: Chaque Qi doit avoir un RQi.
    """
    all_qi = []
    
    for pair in pairs:
        if pair.status != "OK":
            continue
        
        # Nombre de Qi par pair (d√©terministe)
        seed = stable_hash(pair.pair_id)
        n_qi = 3 + (seed % 3)  # 3-5 Qi par pair
        
        # Chapitres disponibles pour ce subject/level
        key = f"{pair.subject_id}|{pair.level_id}"
        chapters = cap.chapters_by_subject_level.get(key, [])
        
        for q in range(n_qi):
            qi_id = f"QI_{pair.pair_id}_{q+1:02d}"
            exo = (q // 2) + 1
            question = (q % 2) + 1
            
            # Texte simul√© (en PROD: extraction OCR)
            raw_text = f"Soit f une fonction. Calculer et d√©montrer propri√©t√© {q+1}."
            
            # RQi (CAS 1 ONLY - obligatoire)
            rqi_text = f"Solution: On applique la m√©thode standard. R√©sultat d√©montr√©."
            
            # Mapping chapitre (d√©terministe bas√© sur position)
            if chapters:
                ch = chapters[q % len(chapters)]
                chapter_code = ch.code
                chapter_label = ch.label
            else:
                chapter_code = None
                chapter_label = None
            
            qi = Qi(
                qi_id=qi_id,
                pair_id=pair.pair_id,
                exo_num=exo,
                question_num=question,
                raw_text=raw_text,
                evidence_hash=sha256(raw_text + qi_id)[:24],
                chapter_code=chapter_code,
                chapter_label=chapter_label,
                rqi_text=rqi_text,
                rqi_hash=sha256(rqi_text)[:24],
                status=QiStatus.POSABLE if chapter_code else QiStatus.QUARANTINE,
                reason_code=ReasonCode.RC_OK if chapter_code else ReasonCode.RC_SCOPE_UNRESOLVED,
            )
            all_qi.append(qi)
    
    posable = len([q for q in all_qi if q.status == QiStatus.POSABLE])
    gate = GateResult(
        "GATE_QI_POSABLE",
        posable > 0,
        {"total": len(all_qi), "posable": posable},
        f"Qi: {len(all_qi)}, POSABLE: {posable}"
    )
    
    return all_qi, gate

# =============================================================================
# CLUSTERING + QC BUILD (Anti-singleton: n_q_cluster >= 2)
# =============================================================================
def cluster_and_build_qc(qi_list: List[Qi], cap: CAP) -> Tuple[List[QC], List[Qi], GateResult]:
    """
    Clustering Qi par chapitre puis construction QC.
    Anti-singleton: n_q_cluster >= 2 obligatoire.
    """
    # Cluster par chapitre
    clusters = defaultdict(list)
    for qi in qi_list:
        if qi.status == QiStatus.POSABLE and qi.chapter_code:
            clusters[qi.chapter_code].append(qi)
    
    qc_list = []
    orphans = []
    
    # Table cognitive (poids T_j) - Kernel invariant
    cognitive_table = {
        "IDENTIFIER": 0.15,
        "CALCULER": 0.25,
        "APPLIQUER": 0.30,
        "ANALYSER": 0.35,
        "COMPARER": 0.35,
        "DEDUIRE": 0.40,
        "DEMONTRER": 0.50,
        "RECURRENCE": 0.60,
    }
    
    for chapter_code, cluster in clusters.items():
        # Anti-singleton: n_q_cluster >= 2
        if len(cluster) < 2:
            for qi in cluster:
                qi.status = QiStatus.ORPHAN
                qi.reason_code = ReasonCode.RC_SINGLETON
                orphans.append(qi)
            continue
        
        # Trouver chapitre dans CAP
        chapter = next((ch for ch in cap.chapters if ch.code == chapter_code), None)
        if not chapter:
            continue
        
        qc_id = f"QC_{chapter_code}"
        
        # QC text (format "Comment ... ?")
        qc_text = f"Comment r√©soudre un probl√®me de {chapter.label.lower()} ?"
        
        # ARI (d√©riv√© des RQi du cluster)
        # Simulation: s√©quence d'√©tapes cognitives
        ari_steps = [
            {"idx": 1, "type": "IDENTIFIER", "text": "Identifier le type de probl√®me", "T_j": 0.15},
            {"idx": 2, "type": "ANALYSER", "text": "Analyser les donn√©es", "T_j": 0.35},
            {"idx": 3, "type": "APPLIQUER", "text": "Appliquer la m√©thode", "T_j": 0.30},
            {"idx": 4, "type": "CALCULER", "text": "Effectuer les calculs", "T_j": 0.25},
        ]
        
        ari_sig = {
            "A": "R√©solution standard",
            "P": f"Pr√©requis {chapter.label}",
            "O": "RESULT_VALUE",
            "X": ["V√©rification", "Conclusion"],
        }
        
        # FRT (4 blocs obligatoires)
        frt = {
            "usage": f"Quand utiliser: probl√®mes de {chapter.label}",
            "reponse_type": "M√©thode: " + " ‚Üí ".join([s["text"] for s in ari_steps]),
            "pieges": f"Pi√®ges: Oublier les hypoth√®ses, erreurs de calcul",
            "conclusion": "Format final: R√©sultat + justification",
        }
        
        # Triggers (3-7 invariants)
        triggers = [
            f"TYPE:{chapter.code}",
            f"SUBJECT:{chapter.subject_id}",
            f"LEVEL:{chapter.level_id}",
            f"METHOD:STANDARD",
        ]
        
        # F1: Œ®_raw puis Œ®_q normalis√©
        sum_tj = sum(s["T_j"] for s in ari_steps)
        psi_raw = chapter.delta_c * (EPSILON + sum_tj) ** 2
        psi_raw = decimal_round(psi_raw)
        
        # F2 components
        n_q = len(cluster)
        n_total = len([q for q in qi_list if q.chapter_code == chapter_code and q.status == QiStatus.POSABLE])
        
        # IA2 Checks
        ia2_checks = {
            "CHK_POSABLE_VALID": all(q.status == QiStatus.POSABLE for q in cluster),
            "CHK_QC_FORM": qc_text.startswith("Comment") and qc_text.endswith("?"),
            "CHK_NO_LOCAL_CONSTANTS": True,  # V√©rifi√©
            "CHK_FRT_TEMPLATE_OK": all(k in frt for k in ["usage", "reponse_type", "pieges", "conclusion"]),
            "CHK_TRIGGERS_QUALITY": 3 <= len(triggers) <= 7,
            "CHK_ARI_TYPED_ONLY": all("type" in s for s in ari_steps),
            "CHK_CLUSTER_MIN": len(cluster) >= 2,  # Anti-singleton
        }
        ia2_pass = all(ia2_checks.values())
        
        # Lier Qi √† QC
        for qi in cluster:
            qi.qc_id = qc_id
        
        qc = QC(
            qc_id=qc_id,
            chapter_code=chapter_code,
            chapter_label=chapter.label,
            subject_id=chapter.subject_id,
            level_id=chapter.level_id,
            qc_text=qc_text,
            qi_ids=[qi.qi_id for qi in cluster],
            n_q_cluster=len(cluster),
            ari_steps=ari_steps,
            ari_sig=ari_sig,
            frt=frt,
            triggers=triggers,
            psi_raw=psi_raw,
            psi_q=0.0,  # Sera normalis√©
            score_f2=0.0,  # Sera calcul√©
            ia2_checks=ia2_checks,
            ia2_status="PASS" if ia2_pass else "FAIL",
            evidence_pack=[qi.evidence_hash for qi in cluster],
        )
        qc_list.append(qc)
    
    # Normalisation Œ®_q par chapitre (max = 1.0)
    # Grouper par subject_level pour normalisation
    by_subj_level = defaultdict(list)
    for qc in qc_list:
        key = f"{qc.subject_id}|{qc.level_id}"
        by_subj_level[key].append(qc)
    
    for key, qcs in by_subj_level.items():
        max_psi = max(qc.psi_raw for qc in qcs) if qcs else 1.0
        for qc in qcs:
            qc.psi_q = decimal_round(qc.psi_raw / max_psi) if max_psi > 0 else 0.0
            # F2 score
            qc.score_f2 = decimal_round(qc.psi_q * (qc.n_q_cluster / max(1, len(qcs))))
    
    # Gate coverage
    posable_qi = [q for q in qi_list if q.status == QiStatus.POSABLE]
    covered_qi = [q for q in posable_qi if q.qc_id is not None]
    coverage = len(covered_qi) / len(posable_qi) * 100 if posable_qi else 0
    
    gate = GateResult(
        "GATE_COVERAGE_100",
        len(orphans) == 0 and coverage == 100,
        {"qc_count": len(qc_list), "orphans": len(orphans), "coverage": coverage},
        f"QC: {len(qc_list)}, Orphans: {len(orphans)}, Coverage: {coverage:.1f}%"
    )
    
    return qc_list, orphans, gate

# =============================================================================
# PIPELINE PRINCIPAL
# =============================================================================
def activate_country(country_code: str) -> Tuple[RunContext, Optional[CAP], List[ExamPair], List[Qi], List[QC]]:
    """
    ACTIVATE_COUNTRY(country_code) - Kernel V10.6.3
    
    Seule action humaine autoris√©e.
    Tout le reste est automatique.
    """
    run_id = f"RUN_{country_code}_{sha256(country_code + utc_now())[7:19]}"
    run_ctx = RunContext(
        run_id=run_id,
        country_code=country_code,
        timestamp=utc_now(),
        status=RunStatus.RUNNING,
    )
    
    # STEP 1: LOAD_CAP
    cap, cap_gates = load_cap(country_code)
    for g in cap_gates:
        run_ctx.gates[g.code] = g
    
    if cap is None or not all(g.passed for g in cap_gates):
        run_ctx.status = RunStatus.SAFETY_STOP
        return run_ctx, None, [], [], []
    
    # STEP 2: HARVEST PAIRS
    pairs, pairs_gate = harvest_pairs(cap)
    run_ctx.gates[pairs_gate.code] = pairs_gate
    
    if not pairs_gate.passed:
        run_ctx.status = RunStatus.SAFETY_STOP
        return run_ctx, cap, pairs, [], []
    
    # STEP 3: ATOMIZE QI + RQI
    qi_list, qi_gate = atomize_qi_rqi(pairs, cap)
    run_ctx.gates[qi_gate.code] = qi_gate
    
    if not qi_gate.passed:
        run_ctx.status = RunStatus.SAFETY_STOP
        return run_ctx, cap, pairs, qi_list, []
    
    # STEP 4: CLUSTER + BUILD QC
    qc_list, orphans, coverage_gate = cluster_and_build_qc(qi_list, cap)
    run_ctx.gates[coverage_gate.code] = coverage_gate
    
    # Build coverage map
    for qi in qi_list:
        if qi.qc_id:
            run_ctx.coverage_map[qi.qi_id] = qi.qc_id
        else:
            run_ctx.coverage_map[qi.qi_id] = "ORPHAN"
    
    # SATURATION LOG
    run_ctx.saturation_log.append({
        "iteration": 1,
        "new_pairs": len(pairs),
        "new_qi": len(qi_list),
        "new_qc": len(qc_list),
        "orphans": len(orphans),
        "status": "COMPLETE" if len(orphans) == 0 else "HAS_ORPHANS",
    })
    
    # FINAL STATUS
    all_pass = all(g.passed for g in run_ctx.gates.values())
    if all_pass:
        run_ctx.status = RunStatus.SEALED
        seal_data = {
            "run_id": run_id,
            "cap_id": cap.cap_id,
            "qc_count": len(qc_list),
            "coverage": 100 if len(orphans) == 0 else 0,
        }
        run_ctx.seal_hash = sha256(json.dumps(seal_data, sort_keys=True))
    else:
        run_ctx.status = RunStatus.UNVERIFIED
    
    return run_ctx, cap, pairs, qi_list, qc_list

# =============================================================================
# STREAMLIT UI (Read-only - Kernel V10.6.3)
# =============================================================================
def main():
    st.set_page_config(page_title="SMAXIA GTE V9", page_icon="üèõÔ∏è", layout="wide")
    
    # State
    for k in ["run_ctx", "cap", "pairs", "qi", "qc"]:
        if k not in st.session_state:
            st.session_state[k] = None if k in ["run_ctx", "cap"] else []
    
    st.title("üèõÔ∏è SMAXIA GTE ‚Äî Government Test Engine")
    st.caption(f"Kernel {KERNEL_VERSION} | CAS 1 ONLY | TEST ISO-PROD")
    
    # Sidebar
    with st.sidebar:
        st.header("üß≠ Navigation")
        menu = st.radio("Menu", [
            "1Ô∏è‚É£ Activation Pays",
            "2Ô∏è‚É£ CAP",
            "3Ô∏è‚É£ Pairs Sujet+Corrig√©",
            "4Ô∏è‚É£ Qi/RQi/Mapping",
            "5Ô∏è‚É£ QC/ARI/FRT/Triggers",
            "6Ô∏è‚É£ Audit IA2",
            "7Ô∏è‚É£ Coverage & Seal",
        ])
        
        st.markdown("---")
        if st.session_state.run_ctx:
            ctx = st.session_state.run_ctx
            st.success(f"üåç {ctx.country_code}")
            st.metric("Status", ctx.status.value)
            st.metric("Pairs", len(st.session_state.pairs))
            st.metric("Qi POSABLE", len([q for q in st.session_state.qi if q.status == QiStatus.POSABLE]))
            st.metric("QC", len(st.session_state.qc))

    # === PAGE 1: ACTIVATION ===
    if menu == "1Ô∏è‚É£ Activation Pays":
        st.header("üåç Activation Pays")
        st.info("**Doctrine Kernel V10.6.3**: La seule action humaine autoris√©e est ACTIVATE_COUNTRY(country_code)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üá´üá∑ France")
            if st.button("ACTIVATE_COUNTRY('FR')", type="primary", use_container_width=True):
                with st.spinner("Pipeline en cours..."):
                    ctx, cap, pairs, qi, qc = activate_country("FR")
                    st.session_state.run_ctx = ctx
                    st.session_state.cap = cap
                    st.session_state.pairs = pairs
                    st.session_state.qi = qi
                    st.session_state.qc = qc
                st.rerun()
        
        with col2:
            st.subheader("üá®üáÆ C√¥te d'Ivoire")
            if st.button("ACTIVATE_COUNTRY('CI')", type="primary", use_container_width=True):
                with st.spinner("Pipeline en cours..."):
                    ctx, cap, pairs, qi, qc = activate_country("CI")
                    st.session_state.run_ctx = ctx
                    st.session_state.cap = cap
                    st.session_state.pairs = pairs
                    st.session_state.qi = qi
                    st.session_state.qc = qc
                st.rerun()
        
        if st.session_state.run_ctx:
            st.markdown("---")
            ctx = st.session_state.run_ctx
            
            if ctx.status == RunStatus.SEALED:
                st.success(f"### ‚úÖ SEALED ‚Äî {ctx.run_id}")
            elif ctx.status == RunStatus.SAFETY_STOP:
                st.error(f"### ‚õî SAFETY_STOP ‚Äî {ctx.run_id}")
            else:
                st.warning(f"### ‚ö†Ô∏è {ctx.status.value} ‚Äî {ctx.run_id}")
            
            cols = st.columns(4)
            cols[0].metric("Pairs", len(st.session_state.pairs))
            cols[1].metric("Qi", len(st.session_state.qi))
            cols[2].metric("QC", len(st.session_state.qc))
            cols[3].metric("Seal", ctx.seal_hash[:16] if ctx.seal_hash else "N/A")

    # === PAGE 2: CAP ===
    elif menu == "2Ô∏è‚É£ CAP":
        st.header("üì¶ Country Academic Pack")
        if not st.session_state.cap:
            st.warning("Activez d'abord un pays")
            return
        
        cap = st.session_state.cap
        
        # Metadata
        st.subheader("A) METADATA")
        cols = st.columns(4)
        cols[0].metric("CAP ID", cap.cap_id)
        cols[1].metric("Status", cap.status)
        cols[2].metric("Language", cap.language_default)
        cols[3].metric("Chapters", len(cap.chapters))
        
        st.code(f"Fingerprint: {cap.cap_fingerprint_sha256}")
        
        # Sources
        st.subheader("C) HARVEST_SOURCES")
        for src in cap.sources:
            st.markdown(f"- **{src.domain}** (Authority: {src.authority_score}, Type: {src.evidence_type})")
        
        # Chapters by Subject/Level
        st.subheader("B) EDUCATION_SYSTEM ‚Äî Chapitres")
        
        for level in cap.levels:
            with st.expander(f"üìò {level['label']}", expanded=False):
                for subj in cap.subjects:
                    key = f"{subj['subject_id']}|{level['level_id']}"
                    chs = cap.chapters_by_subject_level.get(key, [])
                    if chs:
                        st.markdown(f"**{subj['label']}** ({len(chs)} chapitres)")
                        for ch in chs:
                            st.markdown(f"  - `{ch.code}` {ch.label} (Œ¥c={ch.delta_c})")

    # === PAGE 3: PAIRS ===
    elif menu == "3Ô∏è‚É£ Pairs Sujet+Corrig√©":
        st.header("üìÑ Pairs Sujet + Corrig√©")
        if not st.session_state.pairs:
            st.warning("Activez d'abord un pays")
            return
        
        pairs = st.session_state.pairs
        
        st.metric("Total Pairs (CAS 1 ONLY)", len(pairs))
        
        # Par niveau
        by_level = defaultdict(list)
        for p in pairs:
            by_level[p.level_id].append(p)
        
        for level_id, level_pairs in sorted(by_level.items()):
            with st.expander(f"üìò {level_id} ({len(level_pairs)} pairs)", expanded=False):
                for p in level_pairs:
                    st.markdown(f"- **{p.nom}** ({p.exam_type}) ‚Äî {p.subject_id}")

    # === PAGE 4: QI/RQI ===
    elif menu == "4Ô∏è‚É£ Qi/RQi/Mapping":
        st.header("üî¨ Qi / RQi / Mapping")
        if not st.session_state.qi:
            st.warning("Activez d'abord un pays")
            return
        
        qi_list = st.session_state.qi
        posable = [q for q in qi_list if q.status == QiStatus.POSABLE]
        quarantine = [q for q in qi_list if q.status == QiStatus.QUARANTINE]
        orphan = [q for q in qi_list if q.status == QiStatus.ORPHAN]
        
        cols = st.columns(4)
        cols[0].metric("Total Qi", len(qi_list))
        cols[1].metric("POSABLE", len(posable))
        cols[2].metric("QUARANTINE", len(quarantine))
        cols[3].metric("ORPHAN", len(orphan))
        
        if orphan:
            st.error(f"‚ö†Ô∏è {len(orphan)} Qi ORPHAN (singleton ou non mapp√©es)")
        
        # Par chapitre
        by_chapter = defaultdict(list)
        for qi in qi_list:
            by_chapter[qi.chapter_code or "UNMAPPED"].append(qi)
        
        for ch_code, ch_qis in sorted(by_chapter.items()):
            posable_count = len([q for q in ch_qis if q.status == QiStatus.POSABLE])
            with st.expander(f"üìö {ch_code} ({posable_count} POSABLE / {len(ch_qis)} total)", expanded=False):
                for qi in ch_qis[:5]:
                    st.markdown(f"- `{qi.qi_id}` Ex{qi.exo_num}.Q{qi.question_num} ‚Äî {qi.status.value}")

    # === PAGE 5: QC/ARI/FRT/TRIGGERS ===
    elif menu == "5Ô∏è‚É£ QC/ARI/FRT/Triggers":
        st.header("üéØ QC / ARI / FRT / Triggers")
        if not st.session_state.qc:
            st.warning("Activez d'abord un pays")
            return
        
        qc_list = st.session_state.qc
        cap = st.session_state.cap
        
        ia2_pass = len([q for q in qc_list if q.ia2_status == "PASS"])
        
        cols = st.columns(3)
        cols[0].metric("Total QC", len(qc_list))
        cols[1].metric("IA2 PASS", f"{ia2_pass}/{len(qc_list)}")
        cols[2].metric("Chapitres couverts", len(set(q.chapter_code for q in qc_list)))
        
        # Par niveau puis mati√®re puis chapitre
        for level in cap.levels:
            level_qcs = [q for q in qc_list if q.level_id == level["level_id"]]
            if not level_qcs:
                continue
            
            st.markdown(f"## üìò {level['label']}")
            
            for subj in cap.subjects:
                subj_qcs = [q for q in level_qcs if q.subject_id == subj["subject_id"]]
                if not subj_qcs:
                    continue
                
                st.markdown(f"### {subj['label']}")
                
                for qc in sorted(subj_qcs, key=lambda x: x.chapter_code):
                    status_icon = "‚úÖ" if qc.ia2_status == "PASS" else "‚ùå"
                    with st.expander(f"{status_icon} {qc.chapter_label} ‚Äî {qc.qc_id}", expanded=False):
                        # Metrics
                        c1, c2, c3, c4 = st.columns(4)
                        c1.metric("Œ®q", f"{qc.psi_q:.3f}")
                        c2.metric("n_cluster", qc.n_q_cluster)
                        c3.metric("IA2", qc.ia2_status)
                        c4.metric("Triggers", len(qc.triggers))
                        
                        # QC Text
                        st.info(f"**QC:** {qc.qc_text}")
                        
                        # ARI
                        st.markdown("**ARI (Algorithme de R√©solution Invariant):**")
                        for step in qc.ari_steps:
                            st.markdown(f"  {step['idx']}. [{step['type']}] {step['text']} (T_j={step['T_j']})")
                        
                        # FRT
                        st.markdown("**FRT (Fiche de R√©ponse Type):**")
                        for bloc, content in qc.frt.items():
                            st.markdown(f"  - **{bloc}:** {content}")
                        
                        # Triggers
                        st.markdown("**Triggers:**")
                        st.code(" | ".join(qc.triggers))
                        
                        # Qi associ√©es
                        st.markdown(f"**Qi associ√©es ({qc.n_q_cluster}):**")
                        st.code(", ".join(qc.qi_ids[:5]) + ("..." if len(qc.qi_ids) > 5 else ""))

    # === PAGE 6: AUDIT IA2 ===
    elif menu == "6Ô∏è‚É£ Audit IA2":
        st.header("üìä Audit IA2")
        if not st.session_state.run_ctx:
            st.warning("Activez d'abord un pays")
            return
        
        ctx = st.session_state.run_ctx
        qc_list = st.session_state.qc
        
        # Gates
        st.subheader("Gates")
        all_pass = True
        for code, gate in ctx.gates.items():
            if gate.passed:
                st.success(f"‚úÖ {code} ‚Äî {gate.message}")
            else:
                st.error(f"‚ùå {code} ‚Äî {gate.message}")
                all_pass = False
        
        # IA2 Checks par QC
        st.subheader("IA2 Checks par QC")
        for qc in qc_list:
            with st.expander(f"{'‚úÖ' if qc.ia2_status == 'PASS' else '‚ùå'} {qc.qc_id}", expanded=False):
                for chk, passed in qc.ia2_checks.items():
                    st.markdown(f"{'‚úÖ' if passed else '‚ùå'} {chk}")

    # === PAGE 7: COVERAGE & SEAL ===
    elif menu == "7Ô∏è‚É£ Coverage & Seal":
        st.header("üîí Coverage & Seal")
        if not st.session_state.run_ctx:
            st.warning("Activez d'abord un pays")
            return
        
        ctx = st.session_state.run_ctx
        qi_list = st.session_state.qi
        qc_list = st.session_state.qc
        
        posable = [q for q in qi_list if q.status == QiStatus.POSABLE]
        covered = [q for q in posable if q.qc_id is not None]
        orphans = [q for q in qi_list if q.status == QiStatus.ORPHAN]
        
        coverage = len(covered) / len(posable) * 100 if posable else 0
        
        cols = st.columns(4)
        cols[0].metric("Qi POSABLE", len(posable))
        cols[1].metric("Covered", len(covered))
        cols[2].metric("Orphans", len(orphans))
        cols[3].metric("Coverage", f"{coverage:.1f}%")
        
        # Verdict
        st.markdown("---")
        if ctx.status == RunStatus.SEALED:
            st.success(f"### ‚úÖ CHAPITRE SCELL√â")
            st.code(f"Seal Hash: {ctx.seal_hash}")
        elif len(orphans) > 0:
            st.error(f"### ‚õî NON SCELLABLE ‚Äî {len(orphans)} orphelins")
        else:
            st.warning(f"### ‚ö†Ô∏è {ctx.status.value}")
        
        # Saturation log
        st.subheader("Saturation Log")
        if ctx.saturation_log:
            st.dataframe(ctx.saturation_log, hide_index=True)
        
        # Export
        st.subheader("Export")
        if st.button("üì¶ Export Evidence Pack"):
            evidence = {
                "run_id": ctx.run_id,
                "country_code": ctx.country_code,
                "timestamp": ctx.timestamp,
                "status": ctx.status.value,
                "cap_id": st.session_state.cap.cap_id if st.session_state.cap else None,
                "pairs_count": len(st.session_state.pairs),
                "qi_posable": len(posable),
                "qc_count": len(qc_list),
                "coverage": coverage,
                "gates": {k: {"passed": v.passed, "message": v.message} for k, v in ctx.gates.items()},
                "seal_hash": ctx.seal_hash,
            }
            st.json(evidence)
            st.download_button("‚¨áÔ∏è Download", json.dumps(evidence, indent=2), f"evidence_{ctx.country_code}.json")

if __name__ == "__main__":
    main()
